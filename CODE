import pandas as pd
import unicodedata
import os
import pickle
import pandas
from tqdm.auto import tqdm
def Split_words(comment):
    #từ tiếng nhật cần loại bỏ trước
    List_remove_dup = []
    List_del_alpha = [" the ", " is ", " are "]
    List_del_kata = []
    List_del_kanji = []
    List_data=[]
    # loại bỏ các ký tự
    List_replace_sym = ["、", "。", "※", ":", ",", ".", "(", ")", "・", "&", "!", "[", "]", "「", "_", "」", "*"
                        , "?", "・", "■","/",'\\',"→","⇒","%",'"'] 
    
    #khoảng chữ romaji 
    List_big_alpha = [*range(65, 91)] 
    List_normal_alpha = [*range(97, 123)]
    List_normal_alpha.append(45)
    List_total_alpha = List_big_alpha + List_normal_alpha

    List_number = [*range(48, 58)]
    #Khoảng  chữ tiếng nhật
    # List_hira = [*range(12352, 12448)]
    List_kata = [*range(12448, 12544)]
    List_kanji = [*range(19968, 40880)]

    comment = str(comment)
    comment = comment.lower()
    #đổi chữ về dạng unicodedata
    comment = unicodedata.normalize('NFKC', comment)
    delete_list = []
    a = 0
    #loai bo tu trong ngoac {} va []
    for x in comment:
        if x == "【" or x == "{" or a == 1 :
            delete_list.append(x)
            a = 1
            if x == "】" or x =="}":
                a = 0         
                List_remove_dup.append(''.join(delete_list))
                delete_list = []
    #loại bỏ khỏi chuỗi
    for symbol in (List_replace_sym + List_remove_dup + List_del_alpha + List_del_kata + List_del_kanji):
        comment = comment.replace(symbol, " ")
    cmt_split = comment.strip().split()
    # print(cmt_split)
    #tính giá trị điểm của từng chữ. loại bỏ hiragana
    for group in cmt_split:
        group = group.strip()

        length = len(group)
        for i in range(length):
            if ord(group[i]) in (List_kanji + List_kata + List_total_alpha):
                List_data.append(group[i])
    return(''.join(List_data))

def cal_ascii_ratio(text): #kiểm tra tỉ lệ tiếng anh

    word_list = list(text.replace(' ',''))
    if word_list == []:
        return 0
    is_ascii = list(map(lambda x:x.isascii() , word_list))
    return sum(is_ascii)/len(word_list)

#mở file
pkl_file = "bin/DrivePro.pkl"
with open(pkl_file, 'rb') as f:
    data_Drivepro = pickle.load(f)
column_drive_pro_2 = ("お客さまの声","修理内容/結果","現車点検内容","根本原因:作りこみ要因","対策:作りこみ対策","根本原因:見逃し要因", "対策:見逃し対策")
data = set()
sentences = set()
#Lấy chuỗi tiếng nhật với tỉ lệ tiếng anh dưới 30%
for x in column_drive_pro_2:
    for b in data_Drivepro[x]:
        if type(b) is str:
            if cal_ascii_ratio(b) < 0.5:
                sentences.add(b)
    #loại bỏ hiragana
for s in tqdm(sentences):
    data.add(Split_words(s))
#lưu file
with open(F"file_text_DATA.txt", mode='w') as f:
    for ss in data:
        try :
            f.write(''.join(ss))
            f.write('\n')
        except:
            pass
